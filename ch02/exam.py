# app_multi_agent.py - ì±•í„° 2: Streamlitì„ í™œìš©í•œ ë©€í‹° ì—ì´ì „íŠ¸ êµ¬í˜„
import streamlit as st
from langchain_openai import AzureChatOpenAI
from langchain.schema import HumanMessage, SystemMessage, AIMessage
import os
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# LangChain Azure OpenAI ì„¤ì •
llm = AzureChatOpenAI(
    openai_api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    azure_deployment=os.getenv("AZURE_OPENAI_DEPLOYMENT"),
    api_version=os.getenv("AZURE_OPENAI_API_VERSION", "2023-05-15"),
    temperature=0.7,
)

# todo: í˜ì´ì§€ ì„¤ì •
# st. ...

# ì œëª© ë° ì†Œê°œ
st.title("ğŸ¤– AI í† ë¡  - ë©€í‹° ì—ì´ì „íŠ¸")
st.markdown(
    """
### í”„ë¡œì íŠ¸ ì†Œê°œ
ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ 3ê°œì˜ AI ì—ì´ì „íŠ¸(ì°¬ì„±, ë°˜ëŒ€, ì‹¬íŒ)ê°€ ì‚¬ìš©ìê°€ ì œì‹œí•œ ì£¼ì œì— ëŒ€í•´ í† ë¡ ì„ ì§„í–‰í•©ë‹ˆë‹¤.
ê° AIëŠ” ì„œë¡œì˜ ì˜ê²¬ì„ ë“£ê³  ë°˜ë°•í•˜ë©°, ë§ˆì§€ë§‰ì—ëŠ” ì‹¬íŒ AIê°€ í† ë¡  ê²°ê³¼ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.
"""
)

# ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ì´ˆê¸°í™”

# step : start, pro_round_{n}, con_round_{n}, judge, completed
if "debate_started" not in st.session_state:
    st.session_state.debate_started = False
    st.session_state.round = 0
    st.session_state.max_rounds = 3
    st.session_state.debate_history = []
    st.session_state.judge_verdict = None
    st.session_state.current_step = "start"  # í˜„ì¬ ë‹¨ê³„ ì¶”ì 


# AI ì‘ë‹µ ìƒì„± í•¨ìˆ˜ (ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ í¬í•¨)
def generate_response(prompt, system_prompt, message_history=None):
    messages = [SystemMessage(content=system_prompt)]

    # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ê°€ ìˆìœ¼ë©´ ì¶”ê°€
    if message_history:
        for message in message_history:
            if message["role"] == "assistant":
                messages.append(AIMessage(content=message["content"]))
            else:
                messages.append(
                    HumanMessage(content=f"{message['role']}: {message['content']}")
                )

    # í˜„ì¬ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    messages.append(HumanMessage(content=prompt))

    # todo: LLM í˜¸ì¶œ
    # response = ...
    return response.content


# í† ë¡  ì£¼ì œ ì…ë ¥ ì„¹ì…˜
st.header("í† ë¡  ì£¼ì œ ì…ë ¥")

# todo: í† ë¡  ì£¼ì œ ì…ë ¥
# debate_topic = ...

max_rounds = st.slider("í† ë¡  ë¼ìš´ë“œ ìˆ˜", min_value=1, max_value=5, value=1)
st.session_state.max_rounds = max_rounds

# í† ë¡  ì‹œì‘ ë²„íŠ¼
if not st.session_state.debate_started and st.button("í† ë¡  ì‹œì‘"):
    # ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ì´ˆê¸°í™”
    st.session_state.debate_started = True
    st.session_state.round = 1
    st.session_state.debate_history = []
    st.session_state.judge_verdict = None
    st.session_state.current_step = "pro_round_1"
    # todo: í˜ì´ì§€ ë¦¬ë¡œë“œí•˜ì—¬ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰
    # st. ...


# í† ë¡  ë‹¨ê³„ë³„ ê¸°ëŠ¥ì„ í•¨ìˆ˜ë¡œ ë¶„ë¦¬
def handle_pro_round():
    with st.spinner("ì°¬ì„± ì¸¡ ì˜ê²¬ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):

        if st.session_state.round == 1:
            # ì²« ë²ˆì§¸ ì°¬ì„± ì¸¡ ì˜ê²¬ ìƒì„±
            pro_prompt = f"""
            ë‹¹ì‹ ì€ '{debate_topic}'ì— ëŒ€í•´ ì°¬ì„± ì…ì¥ì„ ê°€ì§„ í† ë¡ ìì…ë‹ˆë‹¤.
            ë…¼ë¦¬ì ì´ê³  ì„¤ë“ë ¥ ìˆëŠ” ì°¬ì„± ì¸¡ ì£¼ì¥ì„ ì œì‹œí•´ì£¼ì„¸ìš”.
            200ì ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
            """
            system_prompt = "ë‹¹ì‹ ì€ ë…¼ë¦¬ì ì´ê³  ì„¤ë“ë ¥ ìˆëŠ” ì°¬ì„± ì¸¡ í† ë¡ ìì…ë‹ˆë‹¤."
        else:
            # ì´ì „ ë°˜ëŒ€ ì¸¡ ì˜ê²¬ì— ëŒ€í•œ ë°˜ë°•
            previous_argument = st.session_state.debate_history[-1]["content"]
            pro_prompt = f"""
            ë‹¹ì‹ ì€ '{debate_topic}'ì— ëŒ€í•´ ì°¬ì„± ì…ì¥ì„ ê°€ì§„ í† ë¡ ìì…ë‹ˆë‹¤.
            ë°˜ëŒ€ ì¸¡ì˜ ë‹¤ìŒ ì£¼ì¥ì— ëŒ€í•´ ë°˜ë°•í•˜ê³ , ì°¬ì„± ì…ì¥ì„ ë” ê°•í™”í•´ì£¼ì„¸ìš”:

            ë°˜ëŒ€ ì¸¡ ì£¼ì¥: "{previous_argument}"

            200ì ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
            """
            system_prompt = "ë‹¹ì‹ ì€ ë…¼ë¦¬ì ì´ê³  ì„¤ë“ë ¥ ìˆëŠ” ì°¬ì„± ì¸¡ í† ë¡ ìì…ë‹ˆë‹¤. ë°˜ëŒ€ ì¸¡ ì£¼ì¥ì— ëŒ€í•´ ì ê·¹ì ìœ¼ë¡œ ë°˜ë°•í•˜ì„¸ìš”."

        pro_argument = generate_response(
            pro_prompt, system_prompt, st.session_state.debate_history
        )

        st.session_state.debate_history.append(
            {"role": "ì°¬ì„± ì¸¡", "content": pro_argument}
        )
        st.session_state.current_step = f"con_round_{st.session_state.round}"


def handle_con_round():
    # todo: ë°˜ëŒ€ ì¸¡ ì˜ê²¬ ìƒì„±
    # ...
    # handle_pro_round ì°¸ì¡°
    # ...


def handle_judge():
    with st.spinner("ì‹¬íŒì´ í† ë¡ ì„ í‰ê°€ ì¤‘ì…ë‹ˆë‹¤..."):
        judge_prompt = f"""
        ë‹¤ìŒì€ '{debate_topic}'ì— ëŒ€í•œ ì°¬ë°˜ í† ë¡ ì…ë‹ˆë‹¤. ê° ì¸¡ì˜ ì£¼ì¥ì„ ë¶„ì„í•˜ê³  í‰ê°€í•´ì£¼ì„¸ìš”.

        í† ë¡  ë‚´ìš©:
        """
        for entry in st.session_state.debate_history:
            judge_prompt += f"\n\n{entry['role']}: {entry['content']}"

        judge_prompt += """
        
        ìœ„ í† ë¡ ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ í¬í•¨í•˜ëŠ” ì‹¬ì‚¬ í‰ê°€ë¥¼ í•´ì£¼ì„¸ìš”:
        1. ì–‘ì¸¡ ì£¼ì¥ì˜ í•µì‹¬ ìš”ì•½
        2. ê° ì¸¡ì´ ì‚¬ìš©í•œ ì£¼ìš” ë…¼ë¦¬ì™€ ì¦ê±°ì˜ ê°•ì ê³¼ ì•½ì 
        3. ì „ì²´ í† ë¡ ì˜ ìŠ¹ìì™€ ê·¸ ì´ìœ 
        4. ì–‘ì¸¡ ëª¨ë‘ì—ê²Œ ê°œì„ ì  ì œì•ˆ
        """
        system_prompt = "ë‹¹ì‹ ì€ ê³µì •í•˜ê³  ë…¼ë¦¬ì ì¸ í† ë¡  ì‹¬íŒì…ë‹ˆë‹¤. ì–‘ì¸¡ì˜ ì£¼ì¥ì„ ë©´ë°€íˆ ê²€í† í•˜ê³  ê°ê´€ì ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”."

        judge_verdict = generate_response(judge_prompt, system_prompt, [])

        st.session_state.judge_verdict = judge_verdict
        st.session_state.current_step = "completed"


def show_progress():
    # í† ë¡  ì§„í–‰ ìƒíƒœ í‘œì‹œ
    if (
        st.session_state.debate_started
        and st.session_state.round <= st.session_state.max_rounds
    ):
        total_steps = (
            st.session_state.max_rounds * 2 + 1
        )  # ê° ë¼ìš´ë“œ ë§ˆë‹¤ ì°¬ì„±/ë°˜ëŒ€ + ì‹¬íŒ
        current_steps = (st.session_state.round - 1) * 2 + (
            1 if st.session_state.current_step.startswith("con") else 0
        )
        if (
            st.session_state.current_step == "judge"
            or st.session_state.current_step == "completed"
        ):
            current_steps = total_steps - 1

        progress = current_steps / total_steps
        st.progress(progress)


# í† ë¡  ì§„í–‰
if st.session_state.debate_started:
    # í† ë¡  ì£¼ì œ í‘œì‹œ
    st.header(f"í† ë¡  ì£¼ì œ: {debate_topic}")

    # í˜„ì¬ ë¼ìš´ë“œ ì •ë³´ - ì‹¬íŒ ë‹¨ê³„ì—ì„œëŠ” ë¼ìš´ë“œ í‘œì‹œ ë°©ì‹ì„ ë‹¤ë¥´ê²Œ ì²˜ë¦¬
    if (
        st.session_state.current_step == "judge"
        or st.session_state.current_step == "completed"
    ):
        st.subheader(f"ìµœì¢… í‰ê°€ ë‹¨ê³„")
    else:
        st.subheader(f"ë¼ìš´ë“œ {st.session_state.round} / {st.session_state.max_rounds}")

    show_progress()

    # ì§„í–‰ ë‹¨ê³„ë³„ ì²˜ë¦¬
    if st.session_state.current_step.startswith("pro_round_"):
        handle_pro_round()
        st.rerun()  # í˜ì´ì§€ ë¦¬ë¡œë“œí•˜ì—¬ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰

    elif st.session_state.current_step.startswith("con_round_"):
        handle_con_round()
        st.rerun()  # í˜ì´ì§€ ë¦¬ë¡œë“œí•˜ì—¬ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰

    elif (
        st.session_state.current_step == "judge"
        and st.session_state.judge_verdict is None
    ):
        handle_judge()
        st.rerun()  # í˜ì´ì§€ ë¦¬ë¡œë“œí•˜ì—¬ ê²°ê³¼ í‘œì‹œ

    # í† ë¡  ë‚´ìš© í‘œì‹œ
    st.header("í† ë¡  ì§„í–‰ ìƒí™©")
    for i, entry in enumerate(st.session_state.debate_history):
        round_num = (i // 2) + 1

        st.subheader(f"ë¼ìš´ë“œ {round_num} - {entry['role']}")
        st.write(entry["content"])
        st.divider()

    # ì‹¬íŒ íŒì • í‘œì‹œ
    if st.session_state.judge_verdict:
        st.header("ğŸ§‘â€âš–ï¸ ì‹¬íŒ í‰ê°€")
        st.write(st.session_state.judge_verdict)

    # ë‹¤ì‹œ ì‹œì‘ ë²„íŠ¼
    if st.session_state.current_step == "completed":
        if st.button("ìƒˆ í† ë¡  ì‹œì‘"):
            st.session_state.debate_started = False
            st.session_state.round = 0
            st.session_state.debate_history = []
            st.session_state.judge_verdict = None
            st.session_state.current_step = "start"
            st.rerun()
