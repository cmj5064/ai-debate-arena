# app_langgraph.py - ì±•í„° 3: LangGraphë¥¼ í™œìš©í•œ AI í† ë¡  ì‹œìŠ¤í…œ êµ¬í˜„
from enum import Enum, auto
import streamlit as st
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.schema import HumanMessage, SystemMessage, AIMessage, Document
from langgraph.graph import StateGraph, END
from typing import Dict, List, TypedDict, Literal
import os
from dotenv import load_dotenv
import wikipedia

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="AI í† ë¡ ", page_icon="ğŸ¤–", layout="wide")

# ì œëª© ë° ì†Œê°œ
st.title("ğŸ¤– AI í† ë¡  - LangGraph & RAG ë²„ì „")
st.markdown(
    """
    ### í”„ë¡œì íŠ¸ ì†Œê°œ
    ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ LangGraphë¥¼ í™œìš©í•˜ì—¬ AI ì—ì´ì „íŠ¸ ê°„ì˜ í† ë¡  ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
    ì°¬ì„± ì¸¡, ë°˜ëŒ€ ì¸¡, ê·¸ë¦¬ê³  ì‹¬íŒ ì—­í• ì˜ AIê°€ ì£¼ì–´ì§„ ì£¼ì œì— ëŒ€í•´ ì²´ê³„ì ìœ¼ë¡œ í† ë¡ ì„ ì§„í–‰í•©ë‹ˆë‹¤.
    RAG(Retrieval-Augmented Generation)ë¥¼ í†µí•´ ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰í•˜ì—¬ ë” ê°•ë ¥í•œ ë…¼ë¦¬ë¥¼ í¼ì¹©ë‹ˆë‹¤.
    """
)

# LLM ì„¤ì •
llm = AzureChatOpenAI(
    openai_api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    azure_deployment=os.getenv("AZURE_OPENAI_DEPLOYMENT"),
    api_version=os.getenv("AZURE_OPENAI_API_VERSION", "2023-05-15"),
    temperature=0.7,
)

# ì„ë² ë”© ì„¤ì •
embeddings = AzureOpenAIEmbeddings(
    model=os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT"),
    openai_api_version="2024-02-01",
    api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
)


# ìœ„í‚¤í”¼ë””ì•„ ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜
def get_wikipedia_content(topic, language="en"):
    try:
        # ì–¸ì–´ ì„¤ì •
        wikipedia.set_lang(language)

        # ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° (ë¨¼ì € ê´€ë ¨ í˜ì´ì§€ ì°¾ê¸°)
        # search_results = # TODO> wikipedia search
        search_results = wikipedia.search(topic)

        if not search_results:
            st.warning(f"{topic}ì— ëŒ€í•œ ìœ„í‚¤í”¼ë””ì•„ í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []

        # ë””ë²„ê¹…ìš© ë©”ì‹œì§€
        st.info(f"'{topic}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼: {', '.join(search_results[:3])}...")

        documents = []

        # ìµœëŒ€ 3ê°œì˜ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ í˜ì´ì§€ ì²˜ë¦¬
        for i, page_title in enumerate(search_results[:3]):
            try:
                # í˜ì´ì§€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                page = wikipedia.page(page_title, auto_suggest=False)

                # ìš”ì•½ ì¶”ê°€
                if page.summary:
                    documents.append(
                        Document(
                            page_content=page.summary,
                            metadata={
                                "source": f"wikipedia-{language}",
                                "section": "summary",
                                "topic": page_title,
                            },
                        )
                    )

                # ë³¸ë¬¸ ì„¹ì…˜ ì¶”ê°€ (ì¼ë¶€ë§Œ)
                content = page.content
                if content:
                    # ë³¸ë¬¸ì„ ì ë‹¹í•œ ê¸¸ì´ë¡œ ì˜ë¼ì„œ ì¶”ê°€
                    max_length = 5000  # ìµœëŒ€ ê¸¸ì´ ì œí•œ
                    if len(content) > max_length:
                        content = content[:max_length]

                    documents.append(
                        Document(
                            page_content=content,
                            metadata={
                                "source": f"wikipedia-{language}",
                                "section": "content",
                                "topic": page_title,
                            },
                        )
                    )
            except (
                wikipedia.exceptions.DisambiguationError,
                wikipedia.exceptions.PageError,
            ) as e:
                # ë‹¨ì¼ í˜ì´ì§€ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
                st.warning(f"{page_title} í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                continue

        if documents:
            st.success(f"{language} ì–¸ì–´ë¡œ {len(documents)}ê°œì˜ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

        return documents

    except Exception as e:
        st.error(f"ìœ„í‚¤í”¼ë””ì•„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []


# Vector Store ìƒì„± í•¨ìˆ˜
# TODO: cache
@st.cache_resource
def create_vector_store(topic):
    documents = []

    # ì˜ì–´ ìœ„í‚¤í”¼ë””ì•„ ë°ì´í„° ìˆ˜ì§‘
    wiki_docs_en = get_wikipedia_content(topic, "en")
    # TODO: wiki_docs_enê°€ Noneì´ ì•„ë‹ˆë©´ documentsì— ì¶”ê°€
    if wiki_docs_en:
        documents.extend(wiki_docs_en)
    

    # í•œêµ­ì–´ ìœ„í‚¤í”¼ë””ì•„ ë°ì´í„° ìˆ˜ì§‘
    wiki_docs_ko = get_wikipedia_content(topic, "ko")
    # TODO: wiki_docs_enê°€ Noneì´ ì•„ë‹ˆë©´ documentsì— ì¶”ê°€
    if wiki_docs_ko:
        documents.extend(wiki_docs_ko)

    # í† í”½ì´ ì˜ì–´ê°€ ì•„ë‹Œ ê²½ìš° ì˜ì–´ë¡œë„ ê²€ìƒ‰ ì‹œë„
    if not any(c.isascii() for c in topic):
        # í•œêµ­ì–´ ì£¼ì œë¥¼ ì˜ì–´ë¡œ ë³€í™˜í•˜ë ¤ëŠ” ì‹œë„
        try:
            english_topic = f"{topic} in English"
            additional_docs = get_wikipedia_content(english_topic, "en")
            if additional_docs:
                documents.extend(additional_docs)
        except:
            pass

    # Vector DB ìƒì„±
    if documents:
        try:
            vector_store = FAISS.from_documents(documents, embeddings)
            return vector_store
        except Exception as e:
            st.error(f"Vector DB ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
    else:
        return None


# ê´€ë ¨ ì •ë³´ ê²€ìƒ‰
def retrieve_relevant_info(query, vector_store, k=3):
    if not vector_store:
        return "", []

    try:
        # TODO: ì§ˆì˜ì— ê´€ë ¨ëœ ë¬¸ì„œ ê²€ìƒ‰
        retrieved_docs = vector_store.similarity_search(query, k=k)

        # ê²€ìƒ‰ ê²°ê³¼ í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        context = ""
        for i, doc in enumerate(retrieved_docs):
            source = doc.metadata.get("source", "Unknown")
            section = doc.metadata.get("section", "")
            context += f"[ë¬¸ì„œ {i+1}] ì¶œì²˜: {source}"
            if section:
                context += f", ì„¹ì…˜: {section}"
            context += f"\n{doc.page_content}\n\n"

        return context, retrieved_docs
    except:
        return "", []


# í† ë¡ ì ì—­í• ì„ ìœ„í•œ Enum
class SpeakerRole(Enum):
    PRO = "pro_agent"
    CON = "con_agent"
    JUDGE = "judge"
    COMPLETED = "completed"


# í† ë¡  ìƒíƒœë¥¼ ìœ„í•œ Enum
class DebateStatus(Enum):
    ACTIVE = auto()
    JUDGED = auto()
    COMPLETED = auto()


# LangGraph ìƒíƒœ ì •ì˜ - RAG ê´€ë ¨ í•„ë“œ ì¶”ê°€
class DebateState(TypedDict):
    topic: str
    messages: List[Dict]
    current_round: int
    max_rounds: int
    current_speaker: SpeakerRole
    debate_status: DebateStatus
    vector_store: object  # RAG ë²¡í„° ìŠ¤í† ì–´
    retrieved_docs: Dict[str, List]  # RAG ê²€ìƒ‰ ê²°ê³¼


# ì°¬ì„± ì¸¡ ì—ì´ì „íŠ¸ ë…¸ë“œ - RAG í™œìš©
def pro_agent(state: DebateState) -> DebateState:
    """ì°¬ì„± ì¸¡ ì—ì´ì „íŠ¸ í•¨ìˆ˜"""
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
    system_prompt = "ë‹¹ì‹ ì€ ë…¼ë¦¬ì ì´ê³  ì„¤ë“ë ¥ ìˆëŠ” ì°¬ì„± ì¸¡ í† ë¡ ìì…ë‹ˆë‹¤."

    # ë©”ì‹œì§€ ì¤€ë¹„
    messages = [SystemMessage(content=system_prompt)]

    # ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ì¶”ê°€
    for msg in state["messages"]:
        if msg["role"] == "assistant":
            messages.append(AIMessage(content=msg["content"]))
        else:
            messages.append(HumanMessage(content=f"{msg['role']}: {msg['content']}"))

    # RAG: ê´€ë ¨ ì •ë³´ ê²€ìƒ‰
    query = f"{state['topic']} ì°¬ì„± ì¥ì  ì´ìœ  ê·¼ê±°"
    if state["current_round"] > 1 and state["messages"]:
        # ì´ì „ ë°˜ëŒ€ ì¸¡ ì£¼ì¥ì´ ìˆìœ¼ë©´ ì°¸ê³ 
        prev_con_arguments = [m for m in state["messages"] if m["role"] == "ë°˜ëŒ€ ì¸¡"]
        if prev_con_arguments:
            last_con = prev_con_arguments[-1]["content"]
            query += f" {last_con}ì— ëŒ€í•œ ë°˜ë°•"

    context, docs = "", []
    # if "vector_store" in state and state["vector_store"]:
    vector_store = state.get("vector_store")
    if vector_store:
        context, docs = retrieve_relevant_info(query, state["vector_store"])

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    if state["current_round"] == 1:
        prompt = f"""
        ë‹¹ì‹ ì€ '{state['topic']}'ì— ëŒ€í•´ ì°¬ì„± ì…ì¥ì„ ê°€ì§„ í† ë¡ ìì…ë‹ˆë‹¤.
        
        ë‹¤ìŒì€ ì´ ì£¼ì œì™€ ê´€ë ¨ëœ ì •ë³´ì…ë‹ˆë‹¤:
        {context}
        
        ë…¼ë¦¬ì ì´ê³  ì„¤ë“ë ¥ ìˆëŠ” ì°¬ì„± ì¸¡ ì£¼ì¥ì„ ì œì‹œí•´ì£¼ì„¸ìš”.
        ê°€ëŠ¥í•œ ê²½ìš° ì œê³µëœ ì •ë³´ì—ì„œ êµ¬ì²´ì ì¸ ê·¼ê±°ë¥¼ ì¸ìš©í•˜ì„¸ìš”.
        2 ~ 3ë¬¸ë‹¨, ê° ë¬¸ë‹¨ì€ 100ìë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """
    else:
        # ì´ì „ ë°œì–¸ìì˜ ë§ˆì§€ë§‰ ë©”ì‹œì§€ë¥¼ ê°€ì ¸ì˜´
        previous_messages = [m for m in state["messages"] if m["role"] == "ë°˜ëŒ€ ì¸¡"]
        if previous_messages:
            last_con_message = previous_messages[-1]["content"]
            prompt = f"""
            ë‹¹ì‹ ì€ '{state['topic']}'ì— ëŒ€í•´ ì°¬ì„± ì…ì¥ì„ ê°€ì§„ í† ë¡ ìì…ë‹ˆë‹¤.
            
            ë‹¤ìŒì€ ì´ ì£¼ì œì™€ ê´€ë ¨ëœ ì •ë³´ì…ë‹ˆë‹¤:
            {context}
            
            ë°˜ëŒ€ ì¸¡ì˜ ë‹¤ìŒ ì£¼ì¥ì— ëŒ€í•´ ë°˜ë°•í•˜ê³ , ì°¬ì„± ì…ì¥ì„ ë” ê°•í™”í•´ì£¼ì„¸ìš”:

            ë°˜ëŒ€ ì¸¡ ì£¼ì¥: "{last_con_message}"

            ê°€ëŠ¥í•œ ê²½ìš° ì œê³µëœ ì •ë³´ì—ì„œ êµ¬ì²´ì ì¸ ê·¼ê±°ë¥¼ ì¸ìš©í•˜ì„¸ìš”.
            2 ~ 3ë¬¸ë‹¨, ê° ë¬¸ë‹¨ì€ 100ìë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
            """

    # LLMì— ìš”ì²­
    messages.append(HumanMessage(content=prompt))
    response = llm.invoke(messages)

    # ìƒíƒœ ì—…ë°ì´íŠ¸
    new_state = state.copy()
    new_state["messages"].append({"role": "ì°¬ì„± ì¸¡", "content": response.content})
    new_state["current_speaker"] = SpeakerRole.CON

    # ê²€ìƒ‰ëœ ë¬¸ì„œ ì €ì¥
    if "retrieved_docs" not in new_state:
        new_state["retrieved_docs"] = {"pro": [], "con": []}
    else:
        new_state["retrieved_docs"] = {
            "pro": state["retrieved_docs"].get("pro", [])
            + ([doc.page_content for doc in docs] if docs else []),
            "con": state["retrieved_docs"].get("con", []),
        }

    return new_state


# ë°˜ëŒ€ ì¸¡ ì—ì´ì „íŠ¸ ë…¸ë“œ - RAG í™œìš©
def con_agent(state: DebateState) -> DebateState:
    """ë°˜ëŒ€ ì¸¡ ì—ì´ì „íŠ¸ í•¨ìˆ˜"""
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
    system_prompt = "ë‹¹ì‹ ì€ ë…¼ë¦¬ì ì´ê³  ì„¤ë“ë ¥ ìˆëŠ” ë°˜ëŒ€ ì¸¡ í† ë¡ ìì…ë‹ˆë‹¤. ì°¬ì„± ì¸¡ ì£¼ì¥ì— ëŒ€í•´ ì ê·¹ì ìœ¼ë¡œ ë°˜ë°•í•˜ì„¸ìš”."

    # ë©”ì‹œì§€ ì¤€ë¹„
    messages = [SystemMessage(content=system_prompt)]

    # ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ì¶”ê°€
    for msg in state["messages"]:
        if msg["role"] == "assistant":
            messages.append(AIMessage(content=msg["content"]))
        else:
            messages.append(HumanMessage(content=f"{msg['role']}: {msg['content']}"))

    # RAG: ê´€ë ¨ ì •ë³´ ê²€ìƒ‰
    query = f"{state['topic']} ë°˜ëŒ€ ë‹¨ì  ë¬¸ì œì  ê·¼ê±°"
    if state["messages"]:
        # ê°€ì¥ ìµœê·¼ ì°¬ì„± ì¸¡ ì£¼ì¥ ì°¸ê³ 
        pro_arguments = [e for e in state["messages"] if e["role"] == "ì°¬ì„± ì¸¡"]
        if pro_arguments:
            last_pro = pro_arguments[-1]["content"]
            query += f" {last_pro}ì— ëŒ€í•œ ë°˜ë°•"

    context, docs = "", []
    if "vector_store" in state and state["vector_store"]:
        context, docs = retrieve_relevant_info(query, state["vector_store"])

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    # ì°¬ì„± ì¸¡ ë§ˆì§€ë§‰ ë©”ì‹œì§€ë¥¼ ê°€ì ¸ì˜´
    previous_messages = [m for m in state["messages"] if m["role"] == "ì°¬ì„± ì¸¡"]
    last_pro_message = previous_messages[-1]["content"]
    prompt = f"""
    ë‹¹ì‹ ì€ '{state['topic']}'ì— ëŒ€í•´ ë°˜ëŒ€ ì…ì¥ì„ ê°€ì§„ í† ë¡ ìì…ë‹ˆë‹¤.
    
    ë‹¤ìŒì€ ì´ ì£¼ì œì™€ ê´€ë ¨ëœ ì •ë³´ì…ë‹ˆë‹¤:
    {context}
    
    ì°¬ì„± ì¸¡ì˜ ë‹¤ìŒ ì£¼ì¥ì— ëŒ€í•´ ë°˜ë°•í•˜ê³ , ë°˜ëŒ€ ì…ì¥ì„ ì œì‹œí•´ì£¼ì„¸ìš”:

    ì°¬ì„± ì¸¡ ì£¼ì¥: "{last_pro_message}"

    ê°€ëŠ¥í•œ ê²½ìš° ì œê³µëœ ì •ë³´ì—ì„œ êµ¬ì²´ì ì¸ ê·¼ê±°ë¥¼ ì¸ìš©í•˜ì„¸ìš”.
    2 ~ 3ë¬¸ë‹¨, ê° ë¬¸ë‹¨ì€ 100ìë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    """

    # LLMì— ìš”ì²­
    messages.append(HumanMessage(content=prompt))
    response = llm.invoke(messages)

    # ìƒíƒœ ì—…ë°ì´íŠ¸
    new_state = state.copy()
    new_state["messages"].append({"role": "ë°˜ëŒ€ ì¸¡", "content": response.content})
    new_state["current_round"] += 1

    # ê²€ìƒ‰ëœ ë¬¸ì„œ ì €ì¥
    if "retrieved_docs" not in new_state:
        new_state["retrieved_docs"] = {"pro": [], "con": []}
    else:
        new_state["retrieved_docs"] = {
            "pro": state["retrieved_docs"].get("pro", []),
            "con": state["retrieved_docs"].get("con", [])
            + ([doc.page_content for doc in docs] if docs else []),
        }

    # ë‹¤ìŒ ë¼ìš´ë“œ ì—¬ë¶€ ê²°ì •
    if new_state["current_round"] <= new_state["max_rounds"]:
        new_state["current_speaker"] = SpeakerRole.PRO
    else:
        new_state["current_speaker"] = SpeakerRole.JUDGE

    return new_state


# ì‹¬íŒ ì—ì´ì „íŠ¸ ë…¸ë“œ - RAG í™œìš©
def judge_agent(state: DebateState) -> DebateState:
    """ì‹¬íŒ ì—ì´ì „íŠ¸ í•¨ìˆ˜"""
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
    system_prompt = "ë‹¹ì‹ ì€ ê³µì •í•˜ê³  ë…¼ë¦¬ì ì¸ í† ë¡  ì‹¬íŒì…ë‹ˆë‹¤. ì–‘ì¸¡ì˜ ì£¼ì¥ì„ ë©´ë°€íˆ ê²€í† í•˜ê³  ê°ê´€ì ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”."

    # ë©”ì‹œì§€ ì¤€ë¹„
    messages = [SystemMessage(content=system_prompt)]

    # RAG: ê°ê´€ì ì¸ í‰ê°€ë¥¼ ìœ„í•œ ì •ë³´ ê²€ìƒ‰
    query = f"{state['topic']} í‰ê°€ ê¸°ì¤€ ê°ê´€ì  ì‚¬ì‹¤"
    context, _ = "", []
    if "vector_store" in state and state["vector_store"]:
        context, _ = retrieve_relevant_info(query, state["vector_store"], k=2)

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""
    ë‹¤ìŒì€ '{state['topic']}'ì— ëŒ€í•œ ì°¬ë°˜ í† ë¡ ì…ë‹ˆë‹¤. ê° ì¸¡ì˜ ì£¼ì¥ì„ ë¶„ì„í•˜ê³  í‰ê°€í•´ì£¼ì„¸ìš”.
    
    ë‹¤ìŒì€ ì´ ì£¼ì œì™€ ê´€ë ¨ëœ ê°ê´€ì ì¸ ì •ë³´ì…ë‹ˆë‹¤:
    {context}

    í† ë¡  ë‚´ìš©:
    """
    for msg in state["messages"]:
        prompt += f"\n\n{msg['role']}: {msg['content']}"

    prompt += """
    
    ìœ„ í† ë¡ ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ í¬í•¨í•˜ëŠ” ì‹¬ì‚¬ í‰ê°€ë¥¼ í•´ì£¼ì„¸ìš”:
    1. ì–‘ì¸¡ ì£¼ì¥ì˜ í•µì‹¬ ìš”ì•½
    2. ê° ì¸¡ì´ ì‚¬ìš©í•œ ì£¼ìš” ë…¼ë¦¬ì™€ ì¦ê±°ì˜ ê°•ì ê³¼ ì•½ì 
    3. ì „ì²´ í† ë¡ ì˜ ìŠ¹ìì™€ ê·¸ ì´ìœ 
    4. ì–‘ì¸¡ ëª¨ë‘ì—ê²Œ ê°œì„ ì  ì œì•ˆ
    
    ê°€ëŠ¥í•œ ê²½ìš° ì œê³µëœ ê°ê´€ì  ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ í‰ê°€í•´ì£¼ì„¸ìš”.
    """

    # LLMì— ìš”ì²­
    messages.append(HumanMessage(content=prompt))
    response = llm.invoke(messages)

    # ìƒíƒœ ì—…ë°ì´íŠ¸
    new_state = state.copy()
    new_state["messages"].append({"role": "ì‹¬íŒ", "content": response.content})
    new_state["debate_status"] = DebateStatus.COMPLETED
    new_state["current_speaker"] = SpeakerRole.COMPLETED
    return new_state


# TODO: ë¼ìš°í„° í•¨ìˆ˜ ì‘ì„±
def router(state: DebateState) -> Literal["pro_agent", "con_agent", "ì‹¬íŒ", "END"]:
    if state["debate_status"] == DebateStatus.COMPLETED:
        return "END"
    return state["current_speaker"].value

# LangGraph ì›Œí¬í”Œë¡œìš° ì •ì˜
def create_debate_graph() -> StateGraph:
    # ê·¸ë˜í”„ ìƒì„±
    workflow = StateGraph(DebateState)

    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node(SpeakerRole.PRO.value, pro_agent)
    workflow.add_node(SpeakerRole.CON.value, con_agent)
    workflow.add_node(SpeakerRole.JUDGE.value, judge_agent)

    routing_map = {
        SpeakerRole.PRO.value: SpeakerRole.PRO.value,
        SpeakerRole.CON.value: SpeakerRole.CON.value,
        SpeakerRole.JUDGE.value: SpeakerRole.JUDGE.value,
        "END": END,
    }

    # ì—£ì§€ ì •ì˜
    workflow.add_conditional_edges(
        SpeakerRole.PRO.value,
        router,
        routing_map,
    )

    workflow.add_conditional_edges(
        SpeakerRole.CON.value,
        router,
        routing_map,
    )

    workflow.add_conditional_edges(
        SpeakerRole.JUDGE.value,
        router,
        routing_map,
    )

    # ì‹œì‘ ë…¸ë“œ ì„¤ì •
    workflow.set_entry_point(SpeakerRole.PRO.value)

    # ê·¸ë˜í”„ ì»´íŒŒì¼
    return workflow.compile()


# Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§
# ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ì´ˆê¸°í™”
if "debate_active" not in st.session_state:
    st.session_state.debate_active = False
    st.session_state.debate_messages = []
    st.session_state.vector_store = None
    st.session_state.retrieved_docs = {"pro": [], "con": []}

# ì‚¬ì´ë“œë°”: ì„¤ì •
with st.sidebar:
    st.header("í† ë¡  ì„¤ì •")

    # í† ë¡  ì£¼ì œ ì…ë ¥
    debate_topic = st.text_input(
        "í† ë¡  ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”:", "ì¸ê³µì§€ëŠ¥ì´ ì¸ê°„ì˜ ì¼ìë¦¬ë¥¼ ëŒ€ì²´í•´ì•¼ í•œë‹¤"
    )
    max_rounds = st.slider("í† ë¡  ë¼ìš´ë“œ ìˆ˜", min_value=1, max_value=5, value=1)

    # RAG ê¸°ëŠ¥ í™œì„±í™” ì˜µì…˜
    enable_rag = st.checkbox(
        "RAG í™œì„±í™”", value=True, help="ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰í•˜ì—¬ í† ë¡ ì— í™œìš©í•©ë‹ˆë‹¤."
    )
    show_sources = st.checkbox(
        "ì¶œì²˜ í‘œì‹œ", value=True, help="ê²€ìƒ‰ëœ ì •ë³´ì˜ ì¶œì²˜ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."
    )

# í† ë¡  ì‹œì‘ ë²„íŠ¼
if not st.session_state.debate_active and st.button("í† ë¡  ì‹œì‘"):
    st.session_state.vector_store = None
    st.session_state.retrieved_docs = {"pro": [], "con": []}

    # Vector Store ìƒì„± (RAG í™œì„±í™”ëœ ê²½ìš°)
    if enable_rag:
        with st.spinner("ì™¸ë¶€ ì§€ì‹ì„ ìˆ˜ì§‘í•˜ê³  ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            vector_store = create_vector_store(debate_topic)
            st.session_state.vector_store = vector_store

            if vector_store:
                st.success("ì™¸ë¶€ ì§€ì‹ ê²€ìƒ‰ ì¤€ë¹„ ì™„ë£Œ!")
            else:
                st.warning(
                    "ì™¸ë¶€ ì§€ì‹ ê²€ìƒ‰ì„ ìœ„í•œ ì¤€ë¹„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ í† ë¡ ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤."
                )

    # ê·¸ë˜í”„ ìƒì„±
    debate_graph = create_debate_graph()

    # ì´ˆê¸° ìƒíƒœ ì„¤ì •
    initial_state: DebateState = {
        "topic": debate_topic,
        "messages": [],
        "current_round": 1,
        "max_rounds": max_rounds,
        "current_speaker": SpeakerRole.PRO,
        "debate_status": DebateStatus.ACTIVE,
        "vector_store": st.session_state.vector_store,
        "retrieved_docs": {"pro": [], "con": []},
    }

    # í† ë¡  ì‹œì‘
    with st.spinner("í† ë¡ ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤... ì™„ë£Œê¹Œì§€ ì ì‹œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
        # ê·¸ë˜í”„ ì‹¤í–‰ - stream ëŒ€ì‹  invoke ì‚¬ìš©
        result = debate_graph.invoke(initial_state)

        # ê²°ê³¼ë¥¼ ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ì— ì €ì¥
        st.session_state.debate_messages = result["messages"]
        st.session_state.debate_active = True
        st.session_state.retrieved_docs = result.get(
            "retrieved_docs", {"pro": [], "con": []}
        )

    # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ê²°ê³¼ í‘œì‹œ
    st.rerun()

# í† ë¡  ë‚´ìš© í‘œì‹œ
if st.session_state.debate_active:
    # í† ë¡  ì£¼ì œ í‘œì‹œ
    st.header(f"í† ë¡  ì£¼ì œ: {debate_topic}")

    # í† ë¡  ë‚´ìš© í‘œì‹œ
    st.header("í† ë¡  ì§„í–‰ ìƒí™©")

    messages = st.session_state.debate_messages
    total_rounds = len([m for m in messages if m["role"] == "ì°¬ì„± ì¸¡"])

    # ë¼ìš´ë“œë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ í‘œì‹œ
    for round_num in range(1, total_rounds + 1):
        st.subheader(f"ë¼ìš´ë“œ {round_num}")

        # ì´ ë¼ìš´ë“œì˜ ì°¬ì„±ì¸¡ ë©”ì‹œì§€ ì°¾ê¸° (ì¸ë±ìŠ¤ëŠ” (ë¼ìš´ë“œ-1)*2)
        pro_index = (round_num - 1) * 2
        if pro_index < len(messages) and messages[pro_index]["role"] == "ì°¬ì„± ì¸¡":
            with st.container(border=True):
                st.markdown("**ğŸ”µ ì°¬ì„± ì¸¡:**")
                st.write(messages[pro_index]["content"])

        # ì´ ë¼ìš´ë“œì˜ ë°˜ëŒ€ì¸¡ ë©”ì‹œì§€ ì°¾ê¸° (ì¸ë±ìŠ¤ëŠ” (ë¼ìš´ë“œ-1)*2 + 1)
        con_index = (round_num - 1) * 2 + 1
        if con_index < len(messages) and messages[con_index]["role"] == "ë°˜ëŒ€ ì¸¡":
            with st.container(border=True):
                st.markdown("**ğŸ”´ ë°˜ëŒ€ ì¸¡:**")
                st.write(messages[con_index]["content"])

        st.divider()

    # ì‹¬íŒ í‰ê°€ í‘œì‹œ (ë§ˆì§€ë§‰ ë©”ì‹œì§€)
    if messages and messages[-1]["role"] == "ì‹¬íŒ":
        with st.container(border=True):
            st.subheader("ğŸ§‘â€âš–ï¸ ìµœì¢… í‰ê°€")
            st.write(messages[-1]["content"])

    # ê²€ìƒ‰ëœ ì¶œì²˜ ì •ë³´ í‘œì‹œ (ì˜µì…˜ì´ í™œì„±í™”ëœ ê²½ìš°)
    if (
        show_sources
        and st.session_state.retrieved_docs
        and (
            st.session_state.retrieved_docs.get("pro")
            or st.session_state.retrieved_docs.get("con")
        )
    ):
        with st.expander("ì‚¬ìš©ëœ ì°¸ê³  ìë£Œ ë³´ê¸°"):
            st.subheader("ì°¬ì„± ì¸¡ ì°¸ê³  ìë£Œ")
            for i, doc in enumerate(
                st.session_state.retrieved_docs.get("pro", [])[:3]
            ):  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                st.markdown(f"**ì¶œì²˜ {i+1}**")
                st.text(doc[:300] + "..." if len(doc) > 300 else doc)
                st.divider()

            st.subheader("ë°˜ëŒ€ ì¸¡ ì°¸ê³  ìë£Œ")
            for i, doc in enumerate(
                st.session_state.retrieved_docs.get("con", [])[:3]
            ):  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                st.markdown(f"**ì¶œì²˜ {i+1}**")
                st.text(doc[:300] + "..." if len(doc) > 300 else doc)
                st.divider()

    # ë‹¤ì‹œ ì‹œì‘ ë²„íŠ¼
    if st.button("ìƒˆ í† ë¡  ì‹œì‘"):
        st.session_state.debate_active = False
        st.session_state.debate_messages = []
        st.session_state.vector_store = None
        st.session_state.retrieved_docs = {"pro": [], "con": []}
        st.rerun()
